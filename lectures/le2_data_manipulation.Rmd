---
title: "Managing Data in R"
output: ioslides_presentation
author: KEL - Quantitative Methods
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```
## Housekeeping

- You need some data for this class (assignment one)
- If you still do not have data, and do not have a plan to acquire data (e.g. chatting with your advisor, surfing dryad, using some from a cool paper you recently read), we need to speak about your options ASAP.
- Please email me klangwig@vt.edu if you are worried about this.

- **I need your github username turned in before next class**

## Change in Assignment

- Please turn in your GitHub name and the paragraph about your data on canvas. 
    + There is a text entry box to do this under the "assignments" tab. (Don't send me via email or a canvas message.)

- You can turn in your code and **data file** from assignment 1 using GitHub on Thursday. 

      
## Goals

You should be able to

-  read data into R
- understand and control how R represents those data
    - numbers, characters, factors, missing values
- examine the data visually, numerically, textually, etc.

## Representations

Numeric and character types are fairly straightforward, and you rarely
have to worry about when and whether R represents things as integers or *floating point*.

You do need to know about **factors**, and to be aware when your
variables are being treated as such. See lecture 1 for more about factors.

## Missing values

When you input data, you need to be aware of `NA` ("not available"). Your
read function has an option called `na.strings` which you can use to
communicate between R and your CSV files, for example. You need to know
that

- use `is.na()` to test for `NA` values, `na.omit()` to drop them, and the optional `na.rm` argument in some functions (`mean`, `sum`, `median` ...)

## Changing representations

- R has a big suite of functions for creating, testing and changing
representations. 

-These have names like `factor()`, `as.numeric()` and
`is.character()`.

## Examination

You should think creatively, and early on, about how to check your data.
Is it internally consistent? Are there extreme outliers? Are there
typos? Are there certain values that really mean something else?

An American Airlines memo about fuel reporting from the 1980s complained of multiple cases of:

-   Reported departure fuel greater than aircraft capacity
-   Reported departure fuel less than minimum required for trip
-   Reported arrival fuel greater than reported departure fuel


You should think about what you can test, and what you can fix if it's
broken.

## Visualizing data with graphs
Graphical approaches are really useful for data cleaning; we will
discuss this more later on.

To get you started here are just a few:

- `hist`: will make a histogram plot

## Example
```{r batdat, echo=TRUE}
batdat=read.csv("~/Dropbox/teaching/quant grad course/github/klangwig/bat_data.csv")
head(batdat)  

```

## Example Cont. 
```{r unique, echo=TRUE}
unique(batdat$species)
```

## Example Cont. 
```{r hist, echo=TRUE}
hist(batdat$gd)
```

## Some other useful tools
- `dim`: gives the dimensions of the dataframe
- `str`: gives the structure of each variable
- `glimpse`: a dyplr function, that allows for preview as much of each column as possible
- `head`: get the first 6 rows
- `tail`: get the last 6 rows


## How do you clean data? 
What R functions do you know that are useful for examination? What are
your strategies?

## Tidy(ing) data

Hadley Wickham has defined a concept of [tidy
data](http://www.jstatsoft.org/v59/i10/paper), and has
introduced the `tidyverse` package.

-   Each variable is in a column
-   Each observation is in a row
-   "Long" rather than "wide" form
-   Sometimes duplicates data
-   Statistical modeling tools and graphical tools (especially the
    **ggplot2** package) in R work best with long form
    
## An example of tidy data
```{r, out.width = "800px",echo=F}
knitr::include_graphics("tidy_pic.png")
```

##Learning about the tidyverse
- https://www.tidyverse.org

## Putting your data in tidy format
- Discerning what is a variable can be hard when making data files
- For example, species in my bat dataset is usually a single variable
- I usually also include a "count" column (the number of individuals at a site)
- But what if I wanted to test the effect of the count of one species (e.g.MYSE)
  on another? Now MYSE count is actually a variable.

##Example with bat data
```{r counts, echo=F}

batdat=read.csv("~/Dropbox/teaching/quant grad course/github/klangwig/bat_data.csv")

```

What if I wanted to test how the count of MYSE influenced infection in MYLU? I need to MYSE to be a variable

## Spread and Gather - "Old"" way
- the reshape2 package (also by Hadley Wickham) provides some useful tools for this kind of problem
- You can find more information about using melt and cast here:https://www.statmethods.net/management/reshape.html

## Here, we will use spread and gather
```{r spread, echo=T}
library(tidyr)
batdat$lgdL=log10(batdat$gdL)#log the amount of fungus
batcounts<-aggregate(count~species+site+date,data=batdat, FUN=mean) 
#make a df of bat counts
batcounts.wide<-spread(batcounts, species,count,convert=T) 
#spread that dataframe
```
## What do these look like?
```{r examine,echo=FALSE}
head(batcounts)
head(batcounts.wide)
```

## We can make identical dataframes for loads
```{r loads, echo=F}
batloads<-aggregate(lgdL~species+site+date,data=batdat, FUN=mean)
batloads.wide<-spread(batloads, species,lgdL,convert=T)
head(batloads)
head(batloads.wide)
```

## Now, merge dataframes together for wide format
```{r merging, echo=T}
batwide=merge(batloads.wide,batcounts.wide,by=c("site","date"))
#merge df together by site and date
head(batwide)
```

## Or "match" and keep in long format
```{r match, echo=T}
batloads$unique.row.id = paste(batloads$species,batloads$site,batloads$date)
batcounts$unique.row.id = paste(batcounts$species,batcounts$site,batcounts$date)
#dataframe you are bringing to first, and the one you matching from second
batloads$count = batcounts$count[match(batloads$unique.row.id,batcounts$unique.row.id)]
head(batloads)
```


## Here's another example using the newer and more intuitive "pivot"
 Look at some example data that comes with the tidyr package:

```{r view}
fish_encounters
```

## Here is a link to vignette
- https://tidyr.tidyverse.org/articles/pivot.html
- It seems SO much better than 'spread()' and 'gather()'

## Pivot_wider

Using `pivot_wider()` we can specify how the metadata stored become data variables

```{r pivotwide}
fish_encounters %>%
  pivot_wider(names_from = station, values_from = seen)
```

## Fill in 0's

```{r pivotwide0s}
fish_encounters %>%
  pivot_wider(
    names_from = station,
    values_from = seen,
    values_fill = list(seen = 0)
  )
```

## Making a dataframe long (e.g. tidy)
Let's look at an example of an untidy dataframe.
```{r untidy}
head(relig_income)
```


## Make a row for the number of individuals for each religion by income category

```{r income_per_category}
relig_income %>%
  pivot_longer(-religion, names_to = "income", values_to = "count")
#the minus sign says don't include the column religion
#now you have a variable income and a count of the number of people that were in that income class
```

## Another example using temporal data:
The billboard dataset has a row for every week and the rank of that song
```{r billboard}
billboard
```


## We want week to be temporal data, but it has letters in it
- We want names to be a variable called "week" and the values to be a variable called "rank"
- We want to remove NAs because not all songs stay on the charts for 76 weeks
```{r billboard_longer}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

## Changing something to an integer
- We want to turn week into an integer so we can easily determine how long a song was on the charts
```{r replace_weeks}
billboard %>% 
  pivot_longer (
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    names_ptypes = list(week = integer()),
    values_to = "rank",
    values_drop_na = TRUE
)
```


## So how do we create tidy datasets?
 - Make your data as tidy as possible
 - Learn to manipulate data in R and hardcode these changes into your scripts
 - There is no perfect method - each dataset is unique
 - Manipulating data in R is hard, sometimes harder than excel. But learning to do it SO worth it because you will save hours of time for each project you do. 

## Tools

#### base R

-   `reshape`: wide-to-long and vice versa
-   `merge`: join data frames
-   `ave`: compute averages by group
-   `subset`, `[`-indexing: select obs and vars
-   `transform`: modify variables and create new ones
-   `aggregate`: split-apply-summarize
-   `split`, `lapply`, `do.call(rbind())`: split-apply-combine
-   `sort`

## The tidyverse

-   `tidyr` package: `pivot_longer`, `pivot_wider`
-   `dplyr` package:
    -   `mutate`
    -   `select`
    -   `filter`
    -   `group_by`
    -   `summarise`
    -   `arrange`
    
## Group by, Mutate, and Summarise
 - `group_by` is my favorite tidyverse command which has cut my need to write loops in half
 - `group_by` allows you to do calculations on groups of things, for example, by species or year
 
## First load the package
```{r load_tidyverse}
library(tidyverse)
```

## Group by species
```{r group_by_example}
batdat %>% 
  group_by(species) %>% 
    summarise(mean.fungal.loads=mean(lgdL,na.rm=TRUE))
```

##Summarise versus Mutate
 - `summarise` creates a new dataframe 
 - `mutate` does a calculation where it add a new column to your existing dataframe
 
```{r mutate example}
batdat_with_sample_size = batdat %>% 
  #create a new dataframe  called batdat_with_sample_size
    group_by(site,species,date) %>% 
  #you can group_by multiple things
    mutate(sample.size=n())
#this adds a column to the dataframe
```
##What does our dataframe look like now?
```{r looking at new dataframe}
head(batdat_with_sample_size[c(1,6,7,8,12)])
#this is just showing a few columns for effect
```

 
## Managing Pipelines in R
- Pipelines are ways of carefully recording and systematizing the steps you take to work with your data

- The idea is that you should be able to delete any results of computer calculations and be able to quickly re-do them

- Ideally your project will depend on:
- Some data files
- Some scripts
- Something that tells you how these things go together (RMarkdown is helpful for this), at minimum a README file

## Advantages of this approach
 - Clarity: we aren't confused about the 600 pages of information stored with our projects
 
 - Reproducibility: we can always re-do something we did
 
 - Flexibility : we can use different data and re-create the same thing
 
## Spreadsheets
- Spreadsheets are a useful (and obvious) tool for working with R
- `read.csv` and `write.csv` are very useful commands for working with spreadsheets
- when using `write.csv` use `row.names=F` to avoid line numbers
- Importantly, spreadsheets are for storing data, NOT FOR MANIPULATING DATA

- Your goal should be to take data from a spreadsheet and manipulate it entirely using scripts. 
- Avoid spreadsheet addiction: http://www.burns-stat.com/documents/tutorials/spreadsheet-addiction/ 
- The jist is: friends don't let friends use excel for statistics. 

## Database
- Your spreadsheet is a database (just because it isn't stored in microsoft access doesn't mean it isn't!)
- "small" databases are usually considered to be fewer than 1000 observations of 10-20 vars
- "medium" databases are about 1000 to 100,000 observations of about 10-50 vars. These are most helpful with data handling packages. 
- "large" means millions of observations and potentially 1000s of variables. These may need to be stored in an external application. 

## Working in Github
- Git is version control system, with the original purpose of allowing groups to work collaboratively on software projects
- Git manages the evolution of a set of files - called a repository
- A repository is essentially a folder where you store your stuff
- Version control works a bit like "Track Changes" in word, Git will track the changes we make to our code so we can return to previous versions
- It also allows collaboration so I can look at your code and make changes - a bit like a more complicated version of Google Docs

##Will this hurt?
- Maybe! 

- But, I think this important enough that we NEED exposure to this. This is the future! 

## But I only code alone! 
- You need to carefully document your steps if the only person you are sharing code with is the future version of yourself

- In addition, most journals require publicly available data and code  - open code is the norm, not the exception.

- Using Git has gotten easier. We used to have to use command line to communicate with Git, but now we can just use RStudio! 

##Terminology

- repository: A directory or storage space where your projects can live. Sometimes GitHub users shorten this to “repo.” (If you're cool like that.) It is usually a local folder on your computer. You can keep code files, text files, image files, you name it, inside a repository.

- commit: This is the command that gives Git its power. When you commit, you are taking a “snapshot” of your repository at that point in time, giving you a checkpoint to which you can reevaluate or restore your project to any previous state.When you first start "commiting", it is important to remember this is taking the picture, not SENDING the picture. (Sending is called "pushing")

##Terminology cont.

- branch: How do multiple people work on a project at the same time without Git getting them confused? Usually, they “branch off” of the main project with their own versions full of changes they themselves have made. After they’re done, it’s time to “merge” that branch back with the “master,” the main directory of the project. Because we'll be working within our own repos, we don't need to worry too much about branching but is good to know for future.

- push: This is how you upload your file to GitHub. Remember, you need to both commit and push for your file to be sent to GitHub. 

## Sending your files to our class repository

- We have an "organization" account for our class
- Normally, we would have to pay for private repositories, but I emailed github and they are giving us UNLIMITED private repositories. That's pretty awesome.
- Why should we want things open-source? Why not? 

## Installing Git
 - Please try to start this before our next class. 
 - Here is a link: http://happygitwithr.com/install-git.html#install-git
 - Please follow instructions to get started with git. 
 - Try to install git in the most scientific way possible - if one way doesn't work, try the next, and google your mistakes! 
 



